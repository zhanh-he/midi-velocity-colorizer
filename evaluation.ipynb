{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results in SMD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No runs to be synced.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: NOTE: use \u001b[33mwandb sync --clean\u001b[0m to delete 21 synced runs from local directory.\n",
      "Found 3 checkpoints to evaluate\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/UNet-t10-attn2-CombLoss/epoch=204.ckpt\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=204.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=204.ckpt\n",
      "Testing DataLoader 0: 100%|█████████████████████| 49/49 [00:06<00:00,  7.49it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            11.196952819824219\n",
      "        test_mse             217.489990234375\n",
      "       test_recall          0.6512307524681091\n",
      "     test_recall_5%         0.3787156045436859\n",
      "         test_sd            11.076454162597656\n",
      "       test_sd_ae            9.153830528259277\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/UNet-t10-attn2-CombLoss/epoch=209.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=209.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=209.ckpt\n",
      "Testing DataLoader 0: 100%|█████████████████████| 49/49 [00:04<00:00,  9.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            11.310551643371582\n",
      "        test_mse            221.60659790039062\n",
      "       test_recall          0.6464682817459106\n",
      "     test_recall_5%         0.37459853291511536\n",
      "         test_sd            11.066163063049316\n",
      "       test_sd_ae            9.232372283935547\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/UNet-t10-attn2-CombLoss/epoch=214.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=214.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=214.ckpt\n",
      "Testing DataLoader 0: 100%|█████████████████████| 49/49 [00:04<00:00, 10.27it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            11.197307586669922\n",
      "        test_mse            217.53170776367188\n",
      "       test_recall          0.6510183811187744\n",
      "     test_recall_5%         0.3790575861930847\n",
      "         test_sd            11.151728630065918\n",
      "       test_sd_ae            9.157638549804688\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "# Best model epoch=204 is reported in paper\n",
    "!python train.py exp.test_dataset=\"SMD\" matrix.seg_time=10\\\n",
    "    ae.model=\"UNet\" ae.ablation=\"attn\" ae.attn_window=2\\\n",
    "    exp.testing_only=True exp.group_name=\"2025_ismir\"\\\n",
    "    exp.test_ckpt_dir=\"results/checkpoints/UNet-t10-attn2-CombLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No runs to be synced.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: NOTE: use \u001b[33mwandb sync --clean\u001b[0m to delete 24 synced runs from local directory.\n",
      "Found 3 checkpoints to evaluate\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/ConvAE-t10-CombLoss/epoch=289.ckpt\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at results/checkpoints/ConvAE-t10-CombLoss/epoch=289.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/ConvAE-t10-CombLoss/epoch=289.ckpt\n",
      "Testing DataLoader 0: 100%|█████████████████████| 49/49 [00:04<00:00, 11.45it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            12.529890060424805\n",
      "        test_mse            258.05462646484375\n",
      "       test_recall          0.5846324563026428\n",
      "     test_recall_5%         0.3298983573913574\n",
      "         test_sd             9.810882568359375\n",
      "       test_sd_ae            9.59108829498291\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/ConvAE-t10-CombLoss/epoch=294.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/ConvAE-t10-CombLoss/epoch=294.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/ConvAE-t10-CombLoss/epoch=294.ckpt\n",
      "Testing DataLoader 0: 100%|█████████████████████| 49/49 [00:05<00:00,  8.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            12.522350311279297\n",
      "        test_mse            257.83563232421875\n",
      "       test_recall          0.5852550864219666\n",
      "     test_recall_5%         0.33000269532203674\n",
      "         test_sd             9.82107925415039\n",
      "       test_sd_ae            9.589845657348633\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/ConvAE-t10-CombLoss/epoch=299.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/ConvAE-t10-CombLoss/epoch=299.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/ConvAE-t10-CombLoss/epoch=299.ckpt\n",
      "Testing DataLoader 0: 100%|█████████████████████| 49/49 [00:04<00:00,  9.87it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            12.513594627380371\n",
      "        test_mse            257.55047607421875\n",
      "       test_recall          0.5855937600135803\n",
      "     test_recall_5%         0.3303709626197815\n",
      "         test_sd             9.83485221862793\n",
      "       test_sd_ae            9.586308479309082\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "# Best model epoch=299 is reported in paper\n",
    "!python train.py exp.test_dataset=\"SMD\" matrix.seg_time=10\\\n",
    "    ae.model=\"ConvAE\"\\\n",
    "    exp.testing_only=True exp.group_name=\"2025_ismir\"\\\n",
    "    exp.test_ckpt_dir=\"results/checkpoints/ConvAE-t10-CombLoss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results in MAESTRO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No runs to be synced.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: NOTE: use \u001b[33mwandb sync --clean\u001b[0m to delete 33 synced runs from local directory.\n",
      "Found 3 checkpoints to evaluate\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/UNet-t10-attn2-CombLoss/epoch=204.ckpt\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=204.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=204.ckpt\n",
      "Testing DataLoader 0: 100%|███████████████████| 177/177 [00:21<00:00,  8.33it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            11.487375259399414\n",
      "        test_mse            225.97654724121094\n",
      "       test_recall          0.6364632248878479\n",
      "     test_recall_5%         0.36667150259017944\n",
      "         test_sd             10.76235294342041\n",
      "       test_sd_ae            9.39124870300293\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/UNet-t10-attn2-CombLoss/epoch=209.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=209.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=209.ckpt\n",
      "Testing DataLoader 0: 100%|███████████████████| 177/177 [00:18<00:00,  9.33it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            11.483539581298828\n",
      "        test_mse            226.15634155273438\n",
      "       test_recall           0.637623131275177\n",
      "     test_recall_5%         0.3669089078903198\n",
      "         test_sd            10.708597183227539\n",
      "       test_sd_ae            9.399616241455078\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/UNet-t10-attn2-CombLoss/epoch=214.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=214.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/UNet-t10-attn2-CombLoss/epoch=214.ckpt\n",
      "Testing DataLoader 0: 100%|███████████████████| 177/177 [00:19<00:00,  9.19it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            11.489506721496582\n",
      "        test_mse            226.21485900878906\n",
      "       test_recall           0.636464536190033\n",
      "     test_recall_5%          0.366959810256958\n",
      "         test_sd            10.837645530700684\n",
      "       test_sd_ae            9.401344299316406\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "# Best model epoch=209 is reported in paper\n",
    "!python train.py exp.test_dataset=\"MAESTRO\" matrix.seg_time=10\\\n",
    "    ae.model=\"UNet\" ae.ablation=\"attn\" ae.attn_window=2\\\n",
    "    exp.testing_only=True exp.group_name=\"2025_ismir\"\\\n",
    "    exp.test_ckpt_dir=\"results/checkpoints/UNet-t10-attn2-CombLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No runs to be synced.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: NOTE: use \u001b[33mwandb sync --clean\u001b[0m to delete 30 synced runs from local directory.\n",
      "Found 3 checkpoints to evaluate\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/ConvAE-t10-CombLoss/epoch=289.ckpt\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at results/checkpoints/ConvAE-t10-CombLoss/epoch=289.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/ConvAE-t10-CombLoss/epoch=289.ckpt\n",
      "Testing DataLoader 0: 100%|███████████████████| 177/177 [00:17<00:00,  9.84it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            12.333276748657227\n",
      "        test_mse            250.97909545898438\n",
      "       test_recall           0.593770444393158\n",
      "     test_recall_5%         0.3364255130290985\n",
      "         test_sd             9.715425491333008\n",
      "       test_sd_ae            9.653559684753418\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/ConvAE-t10-CombLoss/epoch=294.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/ConvAE-t10-CombLoss/epoch=294.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/ConvAE-t10-CombLoss/epoch=294.ckpt\n",
      "Testing DataLoader 0: 100%|███████████████████| 177/177 [00:19<00:00,  9.26it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae             12.32923412322998\n",
      "        test_mse             250.8513641357422\n",
      "       test_recall          0.5939932465553284\n",
      "     test_recall_5%         0.3366052806377411\n",
      "         test_sd             9.72573471069336\n",
      "       test_sd_ae            9.652534484863281\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Testing checkpoint: results/checkpoints/ConvAE-t10-CombLoss/epoch=299.ckpt\n",
      "Restoring states from the checkpoint path at results/checkpoints/ConvAE-t10-CombLoss/epoch=299.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at results/checkpoints/ConvAE-t10-CombLoss/epoch=299.ckpt\n",
      "Testing DataLoader 0: 100%|███████████████████| 177/177 [00:18<00:00,  9.67it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "        test_mae            12.325684547424316\n",
      "        test_mse             250.7471923828125\n",
      "       test_recall          0.5942339301109314\n",
      "     test_recall_5%         0.3368000090122223\n",
      "         test_sd             9.740767478942871\n",
      "       test_sd_ae             9.6520414352417\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    }
   ],
   "source": [
    "# Best model epoch=299 is reported in paper\n",
    "!python train.py exp.test_dataset=\"MAESTRO\" matrix.seg_time=10\\\n",
    "    ae.model=\"ConvAE\"\\\n",
    "    exp.testing_only=True exp.group_name=\"2025_ismir\"\\\n",
    "    exp.test_ckpt_dir=\"results/checkpoints/ConvAE-t10-CombLoss\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanyu_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
